\section{Discussion}
In the series of simulations just described, we contrasted several analysis methods on a common set of simulated data. These data were generated using a simple PDP neural network based on the patterns of activation over its visible and hidden layers. The activity in hidden layer consisted of learned distributed representations that are challenging to discover, primarily for the four reasons outlined in the introduction. Activation over the units in the visible layers, on the other hand, were consistently localized within and across the 10 simulated datasets. The critical observation is whether each method was able to recover the distributed representations, when they were either consistently localized or ``anatomically dispersed'' within each of these 10 datasets.  

The pattern of results over methods is accounted for by the assumptions each method makes about what ``true'' signal looks like in noisy data. The univariate contrast analysis was never able to identify distributed representations, even when they were encoded by units in exactly the same location across subjects. The searchlight analysis was unable to identify distributed representations if they were sparsely encoded and dispersed throughout the whole hidden layer. LASSO and Ridge regression leveraged the distributed signal in each subject, and were more likely to assign larger weights to the systematic hidden units, no matter how those units were anatomically situated within the data. However, LASSO has a relatively low hit rate (despite reasonable precision for the units that it does identify), while ridge regression always selects all units and there is no principled way to distinguish which units should be disregarded (i.e., it has the lowest possible precision before arbitrary thresholds are imposed). Both methods yield quite inconsistent solutions across subjects, and LASSO's hit rate is particularly low for individual units that are weakly predictive and highly redundant---which is the common assumption about localization of fMRI signal that promotes the practice of spatially smoothing the data. This means that LASSO can obtain solutions that seem to indicate that the underlying signal is sparse and distributed when in fact the underlying signal meets all to standard localist assumptions. In short, the first two methods adhere too strictly to the assumption that information should be similarly located across subjects, while the latter two are too lax.  Our final simulations	considered a novel regularized multi-task regression technique called SOSLasso, which attempts to balance these two extremes. This method was the best fit for these simulated cases.

This pattern of results leaves open the potential that distributed representations may indeed form the bases for many cognitive processes and mental representations, despite not being discovered or even mentioned in a bulk of the neuroimaging literature. Because many methods utilized in the literature would not have discovered distributed representations even if they did exist, there would be extreme interest to revisiting published datasets, not to question their original findings, but to see if, additionally, there is evidence for other forms of representation.

Aside from the theoretical motives to look for distributed representations in neural data, there are empirical indications that cognitive processes are supported by signal that is arrayed in distributed networks throughout the brain. For example, Mitchell et al (2008) learned a generative model that mapped between nouns and whole brain distributed patterns of neural activity via a support set of 25 sensory-motor verbs. The generated patterns were, on average, closer to the true whole-brain pattern for that word than that of a foil, even when the foil noun was from the same semantic category as the target. In this study, there is no feature selection at the level of voxels---the distance between full activation maps are the criteria of interest, and no voxels are treated as more informative than another. The potential importance of considering information from all voxels is underscored by Rish et al (2013), who used Elastic Net (EN) regression (a method that parametrically combines LASSO and Ridge Regression that attempts to perform feature selection over functionally related units) to identify the parts of the brain that contain information about the amount of thermal pain a subject is experiencing or the length of a visually presented bar. Prior work from this research group showed that it was possible to identify a sparse set of voxels that succeed in predicting the magnitude of the stimulus in both tasks (2009, 2010); the later work extended this by using EN to find the best solution using 1000 voxel sampled from anywhere in the brain, then {\em removing} those voxels from the data, and  repeating the analysis to select another set of 1000 voxels. They did this until all voxels were removed. What Rish et al found was that the classifier accuracy decreased very gradually as each set of the 1000 best voxels were eliminated. Furthermore, the difference in classifier accuracy between the original best solution (with access to all voxels) and the solution based on the data after removing 10,000 of the best voxels was not statistically significant (and both were better than chance). Nevertheless, the voxels selected in those two solutions differed dramatically.  The preliminary hypothesis that authors drew from this pattern of results was that some cognitive tasks may not be handled by particular regions, but in highly distributed networks of interacting units.

Another example comes from the working memory literature. Riggall and Postle (2012) presented subjects with moving dot displays that varied along two dimensions: direction and speed. After stimulus presentation, there was a 15 second delay period before being shown a probe stimulus to compare to the initial one. Critically, half way through the delay period a subject would be cued whether to compare the two stimuli on their speed or their direction of motion. The interest was in how the brain represents the dimensions of the initial stimulus during the delay period. The analysis of their fMRI data proceeded in two steps. They first performed a univariate analysis to identify regions of reliable delay period activity in each subject. From this univariate analysis, however, it is not possible to tell what information is driving that activity, because the task requires keeping track of at least two pieces of information: which is the relevant dimension, and the actual stimulus information along that dimension. An area could contain one or the other or both and show a univariate effect. Using MVPA, however, it is possible to assess these regions of delay activity for what kind of information is present. The results were surprising---none of the areas with sustained delay period activity contained information about the stimulus. A whole-brain analysis conducted with ridge regression, however, was able to decode the direction of the moving dot patterns. This suggests that information about the stimulus is represented in a way that violates the localist assumptions inherent in the univariate analysis, and is potential evidence for distributed representation.

Riggal and Postle's (2012) study is an example of how the nature of the neural representations can be more fully understood by combining techniques. Just as no single experiment can answer all questions, no signal analysis of an fMRI can give a complete picture of the neural representations that underly a cognitive task. As seen in the simulations, each method can be seen as succeeding brilliantly in discovering the signal of they kind they were designed to discover, as much as they can be seen as missing important parts of the true signal. By applying multiple methods, however, one can ask different, complementary questions that lead to a more full appreciation of the data.

The being said, the SOSLasso seems exceptionally appropriate for identifying the neural representations of the kind predicted by PDP models. Since the nature of the representation is so central to PDP theory, applying SOSLasso to test for the existence of distributed representations will be a focus of future research. Because PDP models are the foundation of many influential hypotheses that or normal and abnormal cognitive development and impairment, validating it's central assumption in neural data will have broad impact.

%While the application to the star-plus data is an interesting proof of concept, many aspects of the data and the experiment from which the data were derived preclude many important questions from being addressed.  

%Riggall and Postle's (2012) use of multiple methods to interrogate the data and draw conclusions about the nature of  neural representations  leads us to a closing remark about which method is ``best'' or ``right''. Although some methods seemed to ``out perform'' others on our simulated datasets, we are emphatically not making a claim about the universal superiority of one method over another. All have their place; however, all have their biases and limitations. Using one at the  