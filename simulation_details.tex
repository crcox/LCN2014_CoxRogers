\section{Simulation details}
The model outlined above has 36 input units (18 systematic), 14 hidden units (7 systematic), 36 output units (18 systematic), and 22 irrelevant units that do not receive any inputs or outputs. The model's environment consists of 72 input patterns, which are sampled from two domains, distinguishable based on their systematic input. Half of the input patterns activate units from the first 9 systematic input units (domain A items) and the other half activate units from the second 9 systematic input units (domain B items). The construction of these input patterns was carefully balanced, so that every pattern consisted of exactly 2 systematic and 2 arbitrary input units, that every unit was active in exactly 8 input patterns. Arbitrary units were balanced as closely as possible with respect to category. This all ensures that systematic input units are equally weakly informative about what category a thing belongs to, and that arbitrary units are devoid of category information.  

The model was fit in LENS \cite{rohde_lens:_1999} using back-propogation to minimize cross-entropy. The weights were adjusted with momentum and subject to weight decay which decreased the size of all weights by 0.1\% after every epoch. The model was trained 10 times to asymptotic performance with very low error over 1000 epochs. These 10 models were used to generate data for 10 ``subjects'', based on the patterns of activity over the whole network in the presence of each item. Despite being trained on exactly the same 72 items and obtaining the same level of performance, each model learned different internal representations over their hidden units. Each subject's data set is a 1-dimensional vector of values, arranged from the first input unit to the last output unit. Prior to any reordering, the data for each subject contains well localized signal that is consistently located across subjects.

These 10 datasets contain the ``true'' response pattern for each subject to each item. In any real application, true signal is buried in noise. Of course, the properties of this noise and the signal to noise ratio are important considerations in reality; they will be handled very simply in these simulations. All true activation ranges from 0 to 1, and we added a i.i.d Gaussian random value to each unit, N(0,1). 
